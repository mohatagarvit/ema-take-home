{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take Home Task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: This is ONLY necessary in jupyter notebook.\n",
    "# Details: Jupyter runs an event-loop behind the scenes. \n",
    "#          This results in nested event-loops when we start an event-loop to make async queries.\n",
    "#          This is normally not allowed, we use nest_asyncio to allow it for convenience.  \n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index import (\n",
    "    GPTVectorStoreIndex,\n",
    "    GPTListIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    StorageContext\n",
    ")\n",
    "from llama_index.data_structs import Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "We first show how to convert a Document into a set of Nodes, and insert into a DocumentStore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "from llama_index import download_loader, GPTVectorStoreIndex, ServiceContext, StorageContext, load_index_from_storage\n",
    "from pathlib import Path\n",
    "from utils import *\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "\n",
    "urls = [\n",
    "    \"https://stanford-cs324.github.io/winter2022/lectures/introduction/\",\n",
    "    \"https://stanford-cs324.github.io/winter2022/lectures/harms-1/\",\n",
    "    \"https://stanford-cs324.github.io/winter2022/lectures/harms-2/\",\n",
    "    \"https://stanford-cs324.github.io/winter2022/lectures/capabilities/\",\n",
    "]\n",
    "table_urls = [\"https://github.com/Hannibal046/Awesome-LLM#milestone-papers\"]\n",
    "\n",
    "# UnstructuredURLLoader = download_loader(\"UnstructuredURLLoader\")\n",
    "# loader = UnstructuredURLLoader(urls=urls, continue_on_failure=False, headers={\"User-Agent\": \"value\"})\n",
    "# print(loader.load())\n",
    "\n",
    "BeautifulSoupWebReader = download_loader(\"BeautifulSoupWebReader\")\n",
    "loader = BeautifulSoupWebReader()\n",
    "documents = loader.load_data(urls=urls)\n",
    "\n",
    "from llama_index import GPTTreeIndex, SimpleDirectoryReader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support for other data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GarvitMohata\\Downloads\\ema_take_home\\utils.py:108: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 108 of the file C:\\Users\\GarvitMohata\\Downloads\\ema_take_home\\utils.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page)\n"
     ]
    }
   ],
   "source": [
    "# Image\n",
    "from utils import *\n",
    "\n",
    "image_metadata = get_img_metadata(urls)\n",
    "all_images = []\n",
    "for image_m in image_metadata:\n",
    "    image_doc = Document(text=image_m)\n",
    "    all_images.append(image_doc)\n",
    "documents.extend(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables\n",
    "# Direct Querying\n",
    "from utils import *\n",
    "table_loader = get_table_metadata(table_urls)\n",
    "table_docs = [Document(text=t.to_string()) for t in table_loader]\n",
    "documents.extend(table_docs)\n",
    "\n",
    "# Alternatives\n",
    "# Google's TAPAS Model\n",
    "# PandasAIReader = download_loader(\"PandasAIReader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GarvitMohata\\Downloads\\ema_take_home\\utils.py:77: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 77 of the file C:\\Users\\GarvitMohata\\Downloads\\ema_take_home\\utils.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page)\n",
      "C:\\Users\\GarvitMohata\\Downloads\\ema_take_home\\utils.py:186: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 186 of the file C:\\Users\\GarvitMohata\\Downloads\\ema_take_home\\utils.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page)\n"
     ]
    }
   ],
   "source": [
    "#pdfs\n",
    "from utils import *\n",
    "pdf_loader = get_pdf_metadata(urls)\n",
    "pdf_docs = [Document(text=t) for t in pdf_loader]\n",
    "documents.extend(pdf_docs)\n",
    "\n",
    "# fetch detail/title about paper from google search api, knowing author's name, year    \n",
    "# Alternatives\n",
    "# Short Summary (One-line or 50-60 words) for PDFs from Abstract or Complete Document but Abstract and Introduction should be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GarvitMohata\\Downloads\\ema_take_home\\utils.py:149: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 149 of the file C:\\Users\\GarvitMohata\\Downloads\\ema_take_home\\utils.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page)\n"
     ]
    }
   ],
   "source": [
    "#weblinks\n",
    "from utils import *\n",
    "link_loader = get_url_metadata(urls)\n",
    "link_docs = [Document(text=t) for t in link_loader]\n",
    "documents.extend(link_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize service context (set chunk size)\n",
    "service_context = ServiceContext.from_defaults(chunk_size_limit=1024)\n",
    "nodes = service_context.node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize storage context (by default it's in-memory)\n",
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define List Index and Vector Index over Same Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x1c3a2908c40 state=finished raised RateLimitError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\llama_index\\embeddings\\openai.py:150\u001b[0m, in \u001b[0;36mget_embeddings\u001b[1;34m(list_of_text, engine, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m list_of_text \u001b[38;5;241m=\u001b[39m [text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m list_of_text]\n\u001b[1;32m--> 150\u001b[0m data \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mEmbedding\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mlist_of_text, model\u001b[38;5;241m=\u001b[39mengine, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    138\u001b[0m (\n\u001b[0;32m    139\u001b[0m     deployment_id,\n\u001b[0;32m    140\u001b[0m     engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m )\n\u001b[1;32m--> 153\u001b[0m response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    220\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    221\u001b[0m     method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    222\u001b[0m     url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m     request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    229\u001b[0m )\n\u001b[1;32m--> 230\u001b[0m resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 624\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    630\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    631\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    688\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    689\u001b[0m     )\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m list_index \u001b[38;5;241m=\u001b[39m GPTListIndex(nodes, storage_context\u001b[38;5;241m=\u001b[39mstorage_context)\n\u001b[1;32m----> 2\u001b[0m vector_index \u001b[38;5;241m=\u001b[39m \u001b[43mGPTVectorStoreIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\llama_index\\indices\\vector_store\\base.py:44\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex.__init__\u001b[1;34m(self, nodes, index_struct, service_context, storage_context, use_async, store_nodes_override, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_async \u001b[38;5;241m=\u001b[39m use_async\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_nodes_override \u001b[38;5;241m=\u001b[39m store_nodes_override\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     45\u001b[0m     nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[0;32m     46\u001b[0m     index_struct\u001b[38;5;241m=\u001b[39mindex_struct,\n\u001b[0;32m     47\u001b[0m     service_context\u001b[38;5;241m=\u001b[39mservice_context,\n\u001b[0;32m     48\u001b[0m     storage_context\u001b[38;5;241m=\u001b[39mstorage_context,\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     50\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\llama_index\\indices\\base.py:65\u001b[0m, in \u001b[0;36mBaseGPTIndex.__init__\u001b[1;34m(self, nodes, index_struct, storage_context, service_context, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m nodes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     index_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct \u001b[38;5;241m=\u001b[39m index_struct\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mindex_store\u001b[38;5;241m.\u001b[39madd_index_struct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\llama_index\\token_counter\\token_counter.py:78\u001b[0m, in \u001b[0;36mllm_token_counter.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[1;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_llm_predict\u001b[39m(_self: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m wrapper_logic(_self):\n\u001b[1;32m---> 78\u001b[0m         f_return_val \u001b[38;5;241m=\u001b[39m f(_self, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f_return_val\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\llama_index\\indices\\vector_store\\base.py:201\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex.build_index_from_nodes\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;129m@llm_token_counter\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_index_from_nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_index_from_nodes\u001b[39m(\u001b[38;5;28mself\u001b[39m, nodes: Sequence[Node]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m IndexDict:\n\u001b[0;32m    195\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build the index from nodes.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m    NOTE: Overrides BaseGPTIndex.build_index_from_nodes.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m        GPTVectorStoreIndex only stores nodes in document store\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m        if vector store does not store text\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\llama_index\\indices\\vector_store\\base.py:190\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex._build_index_from_nodes\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    188\u001b[0m     run_async_tasks(tasks)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_nodes_to_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index_struct\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\llama_index\\indices\\vector_store\\base.py:166\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex._add_nodes_to_index\u001b[1;34m(self, index_struct, nodes)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nodes:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m embedding_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_embedding_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m new_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39madd(embedding_results)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39mstores_text \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_nodes_override:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m# we need to add the nodes to the index struct and document store\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\llama_index\\indices\\vector_store\\base.py:85\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex._get_node_embedding_results\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m     79\u001b[0m         id_to_embed_map[n\u001b[38;5;241m.\u001b[39mget_doc_id()] \u001b[38;5;241m=\u001b[39m n\u001b[38;5;241m.\u001b[39membedding\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# call embedding model to get embeddings\u001b[39;00m\n\u001b[0;32m     82\u001b[0m (\n\u001b[0;32m     83\u001b[0m     result_ids,\n\u001b[0;32m     84\u001b[0m     result_embeddings,\n\u001b[1;32m---> 85\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_service_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_queued_text_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_id, text_embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result_ids, result_embeddings):\n\u001b[0;32m     87\u001b[0m     id_to_embed_map[new_id] \u001b[38;5;241m=\u001b[39m text_embedding\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\llama_index\\embeddings\\base.py:167\u001b[0m, in \u001b[0;36mBaseEmbedding.get_queued_text_embeddings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m cur_batch_ids \u001b[38;5;241m=\u001b[39m [text_id \u001b[38;5;28;01mfor\u001b[39;00m text_id, _ \u001b[38;5;129;01min\u001b[39;00m cur_batch]\n\u001b[0;32m    166\u001b[0m cur_batch_texts \u001b[38;5;241m=\u001b[39m [text \u001b[38;5;28;01mfor\u001b[39;00m _, text \u001b[38;5;129;01min\u001b[39;00m cur_batch]\n\u001b[1;32m--> 167\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_text_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_batch_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m result_ids\u001b[38;5;241m.\u001b[39mextend(cur_batch_ids)\n\u001b[0;32m    169\u001b[0m result_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\llama_index\\embeddings\\openai.py:267\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_text_embeddings\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_text_embeddings\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[List[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m    261\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get text embeddings.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m    By default, this is a wrapper around _get_text_embedding.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    Can be overriden for batch queries.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_embeddings(\n\u001b[0;32m    268\u001b[0m         texts,\n\u001b[0;32m    269\u001b[0m         engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_engine,\n\u001b[0;32m    270\u001b[0m         deployment_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment_name,\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_kwargs,\n\u001b[0;32m    272\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tenacity\\__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m retry_exc\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n\u001b[0;32m    329\u001b[0m     sleep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(retry_state)\n",
      "\u001b[1;31mRetryError\u001b[0m: RetryError[<Future at 0x1c3a2908c40 state=finished raised RateLimitError>]"
     ]
    }
   ],
   "source": [
    "list_index = GPTListIndex(nodes, storage_context=storage_context)\n",
    "vector_index = GPTVectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Node/Query Engine for these Indices\n",
    "\n",
    "We define a Node and Query Engine for each Index. We then define an outer \"tool\" index to store\n",
    "these Nodes, which can be treated as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m list_index_node \u001b[38;5;241m=\u001b[39m Node(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLecture notes in Introduction.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     doc_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n\u001b[1;32m----> 5\u001b[0m list_query_engine \u001b[38;5;241m=\u001b[39m \u001b[43mlist_index\u001b[49m\u001b[38;5;241m.\u001b[39mas_query_engine(\n\u001b[0;32m      6\u001b[0m     response_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree_summarize\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_async\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m vector_index_node \u001b[38;5;241m=\u001b[39m Node(\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUseful for questions around the author\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms education, from Paul Graham essay on What I Worked On.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     doc_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector_index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m vector_query_engine \u001b[38;5;241m=\u001b[39m vector_index\u001b[38;5;241m.\u001b[39mas_query_engine(\n\u001b[0;32m     13\u001b[0m     response_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree_summarize\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_async\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'list_index' is not defined"
     ]
    }
   ],
   "source": [
    "list_index_node = Node(\n",
    "    \"Lecture notes in Introduction.\",\n",
    "    doc_id=\"list_index\"\n",
    ")\n",
    "list_query_engine = list_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\", use_async=True\n",
    ")\n",
    "vector_index_node = Node(\n",
    "    \"Useful for questions around the author's education, from Paul Graham essay on What I Worked On.\",\n",
    "    doc_id=\"vector_index\"\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\", use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Vector Index Retriever for these Nodes\n",
    "\n",
    "Define a vector index on top of these Nodes which in turn correspond to the underlying query engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 28 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 28 tokens\n"
     ]
    }
   ],
   "source": [
    "# create an outer \"tool\" index to store the underlying index information\n",
    "tool_index = GPTVectorStoreIndex([list_index_node, vector_index_node])\n",
    "# get retriever\n",
    "tool_retriever = tool_index.as_retriever(similarity_top_k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Router Query Engine\n",
    "\n",
    "We define a router query engine using the vector index retriever as input. This retriever will be used to retrieve \"Nodes\" which contain metadata for query engines. We also take as input a function that maps a Node to a query engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def node_to_query_engine(node: Node):\n",
    "    \"\"\"Convert node to query engine.\"\"\"\n",
    "    # NOTE: hardcode mapping in this case\n",
    "    mapping = {\n",
    "        \"list_index\": list_query_engine,\n",
    "        \"vector_index\": vector_query_engine\n",
    "    }\n",
    "    return mapping[node.get_doc_id()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.query_engine.router_query_engine import RetrieverRouterQueryEngine\n",
    "\n",
    "\n",
    "query_engine = RetrieverRouterQueryEngine(\n",
    "    tool_retriever,\n",
    "    node_to_query_engine\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"What are some milestone model architectures and papers in the last few years\"\n",
    "response = query_engine.query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(response))\n",
    "response.get_formatted_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 8 tokens\n",
      "> [retrieve] Total embedding token usage: 8 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 0 tokens\n",
      "> [retrieve] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1670 tokens\n",
      "> [get_response] Total LLM token usage: 1670 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1670 tokens\n",
      "> [get_response] Total LLM token usage: 1670 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "q = 'Which models did Google release in Oct 2018'\n",
    "response = query_engine.query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Google released the BERT model in October 2018.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'> Source (Doc id: a49c4ab3-63b8-41a6-9264-2d5c6ab04913): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nis access. Whereas small...\\n\\n> Source (Doc id: 5893ad92-6232-4079-bfee-ee8770085fe4): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nTrevor Gale, Lauren E. G...'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(str(response))\n",
    "response.get_formatted_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 13 tokens\n",
      "> [retrieve] Total embedding token usage: 13 tokens\n",
      "INFO:llama_index.indices.common_tree.base:> Building index from nodes: 7 chunks\n",
      "> Building index from nodes: 7 chunks\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=3013 request_id=fa6c89527d7ce11bff281573de3e6e6d response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=3013 request_id=fa6c89527d7ce11bff281573de3e6e6d response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=5214 request_id=91fd4d1694cf984628d484c3a28bb3d9 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=5214 request_id=91fd4d1694cf984628d484c3a28bb3d9 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=5713 request_id=c61dc06cec9ecee92c59a91d99d4a095 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=5713 request_id=c61dc06cec9ecee92c59a91d99d4a095 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=6397 request_id=2c5ac75d17aa18210c506ee0bcdb4bd5 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=6397 request_id=2c5ac75d17aa18210c506ee0bcdb4bd5 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=6689 request_id=2be44785152b7866a68efb0559da0426 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=6689 request_id=2be44785152b7866a68efb0559da0426 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=8550 request_id=67b4347b6e1546588f9eabf6e1276c8a response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=8550 request_id=67b4347b6e1546588f9eabf6e1276c8a response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=9542 request_id=05342166798aa1b0e0d3c0a30bc0a8b3 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=9542 request_id=05342166798aa1b0e0d3c0a30bc0a8b3 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=9712 request_id=1600a5b9290c5e5bfe6057b2df1c2cc9 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=9712 request_id=1600a5b9290c5e5bfe6057b2df1c2cc9 response_code=200\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1464 tokens\n",
      "> [get_response] Total LLM token usage: 1464 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 29211 tokens\n",
      "> [get_response] Total LLM token usage: 29211 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "q = \"What are some milestone model architectures and papers in the last few years\"\n",
    "response = query_engine.query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Some milestone model architectures and papers in the last few years include: \n",
      "- BERT (Devlin et al., 2018)\n",
      "- GPT-2 (Radford et al., 2019)\n",
      "- XLNet (Yang et al., 2019)\n",
      "- Transformer-XL (Dai et al., 2019)\n",
      "- RoBERTa (Liu et al., 2019)\n",
      "- ALBERT (Lan et al., 2019)\n",
      "- T5 (Raffel et al., 2019)\n",
      "- GPT-3 (Brown et al., 2020)\n",
      "- ELECTRA (Clark et al., 2020)\n",
      "- Reformer (Kitaev et al., 2020)\n",
      "- BART (Lewis et al., 2020)\n",
      "- Longformer (Beltagy et al., 2020)\n",
      "- CTRL (Keskar et al., 2020)\n",
      "- DeBERTa (He et al., 2020)\n",
      "- SpanBERT (Joshi et al., 2020)\n",
      "- XLM-RoBERTa (Conneau et al., 2020)\n",
      "- MT-DNN (Liu et al., 2019)\n",
      "- ERNIE (Zhang et al., 2019)\n",
      "- XLM (Conneau et al., 2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'> Source (Doc id: b61ffd5a-d0ab-40fa-9961-b053a0fe7b26): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\n  Introduction | CS324  ...\\n\\n> Source (Doc id: 0c891c44-4121-43e8-aa90-939e3cb06cf0): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\n\\\\(p\\\\). In practice, we d...\\n\\n> Source (Doc id: 2314bb85-5f53-4edf-915a-8f85908e3b0e): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\n= 0.4, \\\\quad\\\\quad\\\\quad p...\\n\\n> Source (Doc id: 53d6cd2b-4b54-44bf-82e1-bd4b264e4e8f): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nrepresent an element \\\\(x...\\n\\n> Source (Doc id: c143e8b7-fe6b-4945-96e9-0b0bd91bda0b): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\n\\\\underbrace{p(\\\\text{spee...\\n\\n> Source (Doc id: 0807b8ef-14c1-491c-ac46-aca95459f1bb): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nvalues of \\\\(n\\\\).Now, the...\\n\\n> Source (Doc id: c58a3e9b-272b-4a75-9090-c48de70af0d3): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nand RoBERTa.  Capabiliti...\\n\\n> Source (Doc id: e4bedb3e-ecf6-4e1f-b6a2-3c1592594cfb): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nsupervised learning. In ...\\n\\n> Source (Doc id: 7ed2b0e0-59dd-4335-852b-d1dd3e96554c): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nfinished the program. He...\\n\\n> Source (Doc id: a49c4ab3-63b8-41a6-9264-2d5c6ab04913): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nis access. Whereas small...\\n\\n> Source (Doc id: 5893ad92-6232-4079-bfee-ee8770085fe4): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nTrevor Gale, Lauren E. G...\\n\\n> Source (Doc id: 2cea4eaa-05c5-4547-8a33-b11035e2e92f): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-1/\\n\\n  Harms I | CS324     Link   ...\\n\\n> Source (Doc id: 79b3b6dc-e893-49b6-907d-893ed94cc645): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-1/\\n\\nothers.For example, automatic...\\n\\n> Source (Doc id: e8a546fb-5a97-49b0-9532-8134829d77e6): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-1/\\n\\nare historically discriminate...\\n\\n> Source (Doc id: 9e6dec3f-937d-4e2c-9c1a-afdefa29246f): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-1/\\n\\nmentions 21 definitions). Unf...\\n\\n> Source (Doc id: 1c838181-dba4-472a-8280-63d37b4796a0): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\n  Harms II | CS324     Link  ...\\n\\n> Source (Doc id: 34a45a3b-7d42-4fb5-b474-f42b276a587d): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nlecture, we will discuss two ...\\n\\n> Source (Doc id: 8e7cbd22-a9af-43a1-b3be-0fe079533219): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nand bigotry comes from your p...\\n\\n> Source (Doc id: 8004b04c-e068-49e4-b33d-138539169599): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nsentences from each toxicity ...\\n\\n> Source (Doc id: f8615429-3d89-4aa3-8adb-bcec32502927): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nactors enlists people to crea...\\n\\n> Source (Doc id: 7fa95496-969e-41be-8027-18acbb4f3cba): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\ncontent, but if they can gene...\\n\\n> Source (Doc id: fdb84ee5-41d2-4d51-a3c9-26e5f1ce02e4): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nBalle, Atoosa Kasirzadeh, Zac...\\n\\n> Source (Doc id: a2d03604-5058-4549-95f1-0ab688316884): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\n  Capabilities | CS324  ...\\n\\n> Source (Doc id: ea98ba63-2ec9-4f3b-be69-741e8643ed55): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\norsomething in between (...\\n\\n> Source (Doc id: ada31b75-60f4-414b-b230-7d615a2c60eb): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\nwant to take the arithme...\\n\\n> Source (Doc id: 697e638d-670c-4559-b0eb-deb79cc36e9d): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\nentire text as a prompt ...\\n\\n> Source (Doc id: 3ca65462-38a1-4afe-ab89-fd45bd66c74e): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\nbias towards short answe...\\n\\n> Source (Doc id: 36bf0172-79db-4f25-a244-0f28fbfc1d82): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\ntranslate a sentence in ...\\n\\n> Source (Doc id: 9ccb1b7e-61d2-41b9-847f-92ba7c5c8b2f): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\nBut those who opposed th...'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(str(response))\n",
    "response.get_formatted_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 8 tokens\n",
      "> [retrieve] Total embedding token usage: 8 tokens\n",
      "INFO:llama_index.indices.common_tree.base:> Building index from nodes: 7 chunks\n",
      "> Building index from nodes: 7 chunks\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=1425 request_id=9a76606045b60c014da5246a04a5a8ed response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=1425 request_id=9a76606045b60c014da5246a04a5a8ed response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=1944 request_id=3c7b66ceb9cb88beb20cc527504f9ac9 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=1944 request_id=3c7b66ceb9cb88beb20cc527504f9ac9 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2137 request_id=4ab14555a4d0696fa1c63e301bebc757 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2137 request_id=4ab14555a4d0696fa1c63e301bebc757 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2207 request_id=e4415d461f1b4560ee12dcd64b67d4b0 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2207 request_id=e4415d461f1b4560ee12dcd64b67d4b0 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2207 request_id=c0f839af4a5c66d253200f250d603170 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2207 request_id=c0f839af4a5c66d253200f250d603170 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2388 request_id=a728c0c559b9f87ce707c74ce8dcab9d response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2388 request_id=a728c0c559b9f87ce707c74ce8dcab9d response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2421 request_id=10d4356cad37fd80087b6232e55d6b18 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2421 request_id=10d4356cad37fd80087b6232e55d6b18 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=3180 request_id=3b5b7177b8281ea2db643d4687cb1915 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=3180 request_id=3b5b7177b8281ea2db643d4687cb1915 response_code=200\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 355 tokens\n",
      "> [get_response] Total LLM token usage: 355 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 27183 tokens\n",
      "> [get_response] Total LLM token usage: 27183 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "q = 'Which models did Google release in Oct 2018'\n",
    "q = \"What are the layers in a transformer block\"\n",
    "response = query_engine.query(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The layers in a transformer block are typically composed of a multi-head attention layer, a feed-forward layer, and a layer normalization layer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'> Source (Doc id: b61ffd5a-d0ab-40fa-9961-b053a0fe7b26): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\n  Introduction | CS324  ...\\n\\n> Source (Doc id: 0c891c44-4121-43e8-aa90-939e3cb06cf0): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\n\\\\(p\\\\). In practice, we d...\\n\\n> Source (Doc id: 2314bb85-5f53-4edf-915a-8f85908e3b0e): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\n= 0.4, \\\\quad\\\\quad\\\\quad p...\\n\\n> Source (Doc id: 53d6cd2b-4b54-44bf-82e1-bd4b264e4e8f): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nrepresent an element \\\\(x...\\n\\n> Source (Doc id: c143e8b7-fe6b-4945-96e9-0b0bd91bda0b): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\n\\\\underbrace{p(\\\\text{spee...\\n\\n> Source (Doc id: 0807b8ef-14c1-491c-ac46-aca95459f1bb): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nvalues of \\\\(n\\\\).Now, the...\\n\\n> Source (Doc id: c58a3e9b-272b-4a75-9090-c48de70af0d3): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nand RoBERTa.  Capabiliti...\\n\\n> Source (Doc id: e4bedb3e-ecf6-4e1f-b6a2-3c1592594cfb): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nsupervised learning. In ...\\n\\n> Source (Doc id: 7ed2b0e0-59dd-4335-852b-d1dd3e96554c): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nfinished the program. He...\\n\\n> Source (Doc id: a49c4ab3-63b8-41a6-9264-2d5c6ab04913): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nis access. Whereas small...\\n\\n> Source (Doc id: 5893ad92-6232-4079-bfee-ee8770085fe4): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nTrevor Gale, Lauren E. G...\\n\\n> Source (Doc id: 2cea4eaa-05c5-4547-8a33-b11035e2e92f): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-1/\\n\\n  Harms I | CS324     Link   ...\\n\\n> Source (Doc id: 79b3b6dc-e893-49b6-907d-893ed94cc645): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-1/\\n\\nothers.For example, automatic...\\n\\n> Source (Doc id: e8a546fb-5a97-49b0-9532-8134829d77e6): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-1/\\n\\nare historically discriminate...\\n\\n> Source (Doc id: 9e6dec3f-937d-4e2c-9c1a-afdefa29246f): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-1/\\n\\nmentions 21 definitions). Unf...\\n\\n> Source (Doc id: 1c838181-dba4-472a-8280-63d37b4796a0): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\n  Harms II | CS324     Link  ...\\n\\n> Source (Doc id: 34a45a3b-7d42-4fb5-b474-f42b276a587d): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nlecture, we will discuss two ...\\n\\n> Source (Doc id: 8e7cbd22-a9af-43a1-b3be-0fe079533219): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nand bigotry comes from your p...\\n\\n> Source (Doc id: 8004b04c-e068-49e4-b33d-138539169599): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nsentences from each toxicity ...\\n\\n> Source (Doc id: f8615429-3d89-4aa3-8adb-bcec32502927): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nactors enlists people to crea...\\n\\n> Source (Doc id: 7fa95496-969e-41be-8027-18acbb4f3cba): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\ncontent, but if they can gene...\\n\\n> Source (Doc id: fdb84ee5-41d2-4d51-a3c9-26e5f1ce02e4): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nBalle, Atoosa Kasirzadeh, Zac...\\n\\n> Source (Doc id: a2d03604-5058-4549-95f1-0ab688316884): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\n  Capabilities | CS324  ...\\n\\n> Source (Doc id: ea98ba63-2ec9-4f3b-be69-741e8643ed55): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\norsomething in between (...\\n\\n> Source (Doc id: ada31b75-60f4-414b-b230-7d615a2c60eb): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\nwant to take the arithme...\\n\\n> Source (Doc id: 697e638d-670c-4559-b0eb-deb79cc36e9d): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\nentire text as a prompt ...\\n\\n> Source (Doc id: 3ca65462-38a1-4afe-ab89-fd45bd66c74e): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\nbias towards short answe...\\n\\n> Source (Doc id: 36bf0172-79db-4f25-a244-0f28fbfc1d82): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\ntranslate a sentence in ...\\n\\n> Source (Doc id: 9ccb1b7e-61d2-41b9-847f-92ba7c5c8b2f): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\nBut those who opposed th...'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(str(response))\n",
    "response.get_formatted_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 16 tokens\n",
      "> [retrieve] Total embedding token usage: 16 tokens\n",
      "INFO:llama_index.indices.common_tree.base:> Building index from nodes: 8 chunks\n",
      "> Building index from nodes: 8 chunks\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=4285 request_id=2424d154827e47db1739ba6021e0a124 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=4285 request_id=2424d154827e47db1739ba6021e0a124 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=5350 request_id=0df209add34067cb7bd35cffc15f903e response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=5350 request_id=0df209add34067cb7bd35cffc15f903e response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=5402 request_id=5198bc5a124d5ef544db6618b9af7d0f response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=5402 request_id=5198bc5a124d5ef544db6618b9af7d0f response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=5751 request_id=b909afcb808ac5ade84b4609762cd418 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=5751 request_id=b909afcb808ac5ade84b4609762cd418 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=5897 request_id=c443336269307073600e2b995deca3b1 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=5897 request_id=c443336269307073600e2b995deca3b1 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=6801 request_id=d888add779be7e4884407f163f9173a0 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=6801 request_id=d888add779be7e4884407f163f9173a0 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=7708 request_id=ea75becf0f8a5d55625b411a7e58f16c response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=7708 request_id=ea75becf0f8a5d55625b411a7e58f16c response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=8645 request_id=7537096403cc3cd8d65c5b94ffbebe3b response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=8645 request_id=7537096403cc3cd8d65c5b94ffbebe3b response_code=200\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1354 tokens\n",
      "> [get_response] Total LLM token usage: 1354 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 29023 tokens\n",
      "> [get_response] Total LLM token usage: 29023 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query('Tell me about datasets used to train LLMs and how they’re cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datasets used to train language models (LLMs) are typically large collections of text, such as books, articles, or other documents. These datasets are often pre-processed and cleaned to remove any unwanted content, such as profanity, offensive language, and other inappropriate content. Additionally, the datasets are often filtered to remove any duplicates or near-duplicates, as well as any content that is not relevant to the task at hand. This helps to ensure that the language model is trained on only the most relevant and accurate data. Additionally, the datasets are often annotated with labels or tags to help the model better understand the context of the text. Common datasets used to train language models include the Penn Treebank, the Brown Corpus, and the Google Billion Word Corpus. These datasets are typically pre-processed to remove punctuation, capitalization, and other non-textual elements. Additionally, the datasets are often tokenized, which involves splitting the text into individual words or phrases.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'> Source (Doc id: b61ffd5a-d0ab-40fa-9961-b053a0fe7b26): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\n  Introduction | CS324  ...\\n\\n> Source (Doc id: 0c891c44-4121-43e8-aa90-939e3cb06cf0): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\n\\\\(p\\\\). In practice, we d...\\n\\n> Source (Doc id: 2314bb85-5f53-4edf-915a-8f85908e3b0e): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\n= 0.4, \\\\quad\\\\quad\\\\quad p...\\n\\n> Source (Doc id: 53d6cd2b-4b54-44bf-82e1-bd4b264e4e8f): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nrepresent an element \\\\(x...\\n\\n> Source (Doc id: c143e8b7-fe6b-4945-96e9-0b0bd91bda0b): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\n\\\\underbrace{p(\\\\text{spee...\\n\\n> Source (Doc id: 0807b8ef-14c1-491c-ac46-aca95459f1bb): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nvalues of \\\\(n\\\\).Now, the...\\n\\n> Source (Doc id: c58a3e9b-272b-4a75-9090-c48de70af0d3): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nand RoBERTa.  Capabiliti...\\n\\n> Source (Doc id: e4bedb3e-ecf6-4e1f-b6a2-3c1592594cfb): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nsupervised learning. In ...\\n\\n> Source (Doc id: 7ed2b0e0-59dd-4335-852b-d1dd3e96554c): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nfinished the program. He...\\n\\n> Source (Doc id: a49c4ab3-63b8-41a6-9264-2d5c6ab04913): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nis access. Whereas small...\\n\\n> Source (Doc id: 5893ad92-6232-4079-bfee-ee8770085fe4): URL: https://stanford-cs324.github.io/winter2022/lectures/introduction/\\n\\nTrevor Gale, Lauren E. G...\\n\\n> Source (Doc id: 2cea4eaa-05c5-4547-8a33-b11035e2e92f): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-1/\\n\\n  Harms I | CS324     Link   ...\\n\\n> Source (Doc id: 79b3b6dc-e893-49b6-907d-893ed94cc645): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-1/\\n\\nothers.For example, automatic...\\n\\n> Source (Doc id: e8a546fb-5a97-49b0-9532-8134829d77e6): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-1/\\n\\nare historically discriminate...\\n\\n> Source (Doc id: 9e6dec3f-937d-4e2c-9c1a-afdefa29246f): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-1/\\n\\nmentions 21 definitions). Unf...\\n\\n> Source (Doc id: 1c838181-dba4-472a-8280-63d37b4796a0): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\n  Harms II | CS324     Link  ...\\n\\n> Source (Doc id: 34a45a3b-7d42-4fb5-b474-f42b276a587d): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nlecture, we will discuss two ...\\n\\n> Source (Doc id: 8e7cbd22-a9af-43a1-b3be-0fe079533219): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nand bigotry comes from your p...\\n\\n> Source (Doc id: 8004b04c-e068-49e4-b33d-138539169599): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nsentences from each toxicity ...\\n\\n> Source (Doc id: f8615429-3d89-4aa3-8adb-bcec32502927): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nactors enlists people to crea...\\n\\n> Source (Doc id: 7fa95496-969e-41be-8027-18acbb4f3cba): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\ncontent, but if they can gene...\\n\\n> Source (Doc id: fdb84ee5-41d2-4d51-a3c9-26e5f1ce02e4): URL: https://stanford-cs324.github.io/winter2022/lectures/harms-2/\\n\\nBalle, Atoosa Kasirzadeh, Zac...\\n\\n> Source (Doc id: a2d03604-5058-4549-95f1-0ab688316884): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\n  Capabilities | CS324  ...\\n\\n> Source (Doc id: ea98ba63-2ec9-4f3b-be69-741e8643ed55): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\norsomething in between (...\\n\\n> Source (Doc id: ada31b75-60f4-414b-b230-7d615a2c60eb): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\nwant to take the arithme...\\n\\n> Source (Doc id: 697e638d-670c-4559-b0eb-deb79cc36e9d): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\nentire text as a prompt ...\\n\\n> Source (Doc id: 3ca65462-38a1-4afe-ab89-fd45bd66c74e): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\nbias towards short answe...\\n\\n> Source (Doc id: 36bf0172-79db-4f25-a244-0f28fbfc1d82): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\ntranslate a sentence in ...\\n\\n> Source (Doc id: 9ccb1b7e-61d2-41b9-847f-92ba7c5c8b2f): URL: https://stanford-cs324.github.io/winter2022/lectures/capabilities/\\n\\nBut those who opposed th...'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(str(response))\n",
    "response.get_formatted_sources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt at using Conversational Bot with Conversational Memory\n",
    "- Not working properly \n",
    "- Provided query_engine \n",
    "- Still not using the document information to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Hi Bob, nice to meet you!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Vector Index\n",
      "Action Input: milestone model architectures and papers\u001b[0m\n",
      "Observation: Vector Index is not a valid tool, try another one.\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: Some of the most notable milestone model architectures and papers in the last few years include Google's BERT (Bidirectional Encoder Representations from Transformers), OpenAI's GPT-2 (Generative Pre-trained Transformer 2), and Microsoft's Transformer-XL. Additionally, there have been a number of papers on various topics such as natural language processing, computer vision, and reinforcement learning.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.langchain_helpers.agents import LlamaToolkit, create_llama_chat_agent, IndexToolConfig\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI\n",
    "tool_config = IndexToolConfig(\n",
    "        query_engine=query_engine, \n",
    "        name=f\"Vector Index \",\n",
    "        description=f\"useful for when you want to answer queries about the document\",\n",
    "        tool_kwargs={\"return_direct\": True}\n",
    "    )\n",
    "toolkit = LlamaToolkit(\n",
    "    index_configs=[tool_config],\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "llm = OpenAI(temperature=0)\n",
    "agent_chain = create_llama_chat_agent(\n",
    "    toolkit,\n",
    "    llm,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    ")\n",
    "chat_history = []\n",
    "\n",
    "import gradio as gr\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"Clear\")\n",
    "    chat_history = []\n",
    "    \n",
    "    def user(user_message, history):\n",
    "        # Get response from QA chain\n",
    "        response = agent_chain.run(input=user_message)\n",
    "        # Append user message and response to chat history\n",
    "        history.append((user_message, response)) \n",
    "        return gr.update(value=\"\"), history\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False)\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
